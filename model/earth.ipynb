{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.1033160000000015\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"earthquake_1995-2023.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting features and target variable\n",
        "target = \"magnitude\"\n",
        "features = [\"latitude\", \"longitude\", \"depth\", \"cdi\", \"mmi\", \"tsunami\", \"sig\", \"dmin\", \"gap\", \"nst\", \"magType\"]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "for col in [\"cdi\", \"mmi\", \"sig\", \"dmin\", \"gap\", \"nst\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_features = [\"magType\"]\n",
        "numerical_features = list(set(features) - set(categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "])\n",
        "\n",
        "# Split the dataset\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.1033160000000015\n",
            "R-squared Score: 0.7820859449354391\n",
            "    Actual  Predicted\n",
            "0      7.8      7.448\n",
            "1      6.8      6.798\n",
            "2      6.6      6.599\n",
            "3      6.6      6.597\n",
            "4      6.8      6.866\n",
            "5      7.6      7.183\n",
            "6      7.9      7.418\n",
            "7      6.7      6.747\n",
            "8      6.9      6.900\n",
            "9      6.6      6.599\n",
            "10     6.9      6.899\n",
            "11     7.3      7.132\n",
            "12     6.8      6.952\n",
            "13     7.9      7.882\n",
            "14     6.9      6.897\n",
            "15     6.6      6.600\n",
            "16     7.2      7.153\n",
            "17     6.6      6.600\n",
            "18     6.5      6.500\n",
            "19     7.0      6.812\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"earthquake_1995-2023.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting features and target variable\n",
        "target = \"magnitude\"\n",
        "features = [\"latitude\", \"longitude\", \"depth\", \"cdi\", \"mmi\", \"tsunami\", \"sig\", \"dmin\", \"gap\", \"nst\", \"magType\"]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "for col in [\"cdi\", \"mmi\", \"sig\", \"dmin\", \"gap\", \"nst\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_features = [\"magType\"]\n",
        "numerical_features = list(set(features) - set(categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "])\n",
        "\n",
        "# Split the dataset\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R-squared Score: {r2}\")\n",
        "\n",
        "# Display actual vs predicted values\n",
        "results = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred})\n",
        "print(results.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Mean Absolute Error: 0.1033160000000015, R-squared Score: 0.7820859449354391\n",
            "Gradient Boosting - Mean Absolute Error: 0.11528671279321731, R-squared Score: 0.7632242485596796\n",
            "Linear Regression - Mean Absolute Error: 0.2885600527291944, R-squared Score: 0.212210710487308\n",
            "K-Nearest Neighbors - Mean Absolute Error: 0.28356000000000003, R-squared Score: 0.26261590569135196\n",
            "Support Vector Machine - Mean Absolute Error: 0.16319767777216068, R-squared Score: 0.6541413368002252\n",
            "Best Model: Random Forest\n",
            "    Actual  Predicted\n",
            "0      7.8      7.448\n",
            "1      6.8      6.798\n",
            "2      6.6      6.599\n",
            "3      6.6      6.597\n",
            "4      6.8      6.866\n",
            "5      7.6      7.183\n",
            "6      7.9      7.418\n",
            "7      6.7      6.747\n",
            "8      6.9      6.900\n",
            "9      6.6      6.599\n",
            "10     6.9      6.899\n",
            "11     7.3      7.132\n",
            "12     6.8      6.952\n",
            "13     7.9      7.882\n",
            "14     6.9      6.897\n",
            "15     6.6      6.600\n",
            "16     7.2      7.153\n",
            "17     6.6      6.600\n",
            "18     6.5      6.500\n",
            "19     7.0      6.812\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"earthquake_1995-2023.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting features and target variable\n",
        "target = \"magnitude\"\n",
        "features = [\"latitude\", \"longitude\", \"depth\", \"cdi\", \"mmi\", \"tsunami\", \"sig\", \"dmin\", \"gap\", \"nst\", \"magType\"]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "for col in [\"cdi\", \"mmi\", \"sig\", \"dmin\", \"gap\", \"nst\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_features = [\"magType\"]\n",
        "numerical_features = list(set(features) - set(categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "])\n",
        "\n",
        "# Split the dataset\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define different models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Support Vector Machine\": SVR()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, regressor in models.items():\n",
        "    model = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"regressor\", regressor)\n",
        "    ])\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {\"MAE\": mae, \"R2 Score\": r2}\n",
        "    print(f\"{name} - Mean Absolute Error: {mae}, R-squared Score: {r2}\")\n",
        "\n",
        "# Print actual vs predicted values for the best model (Random Forest as default)\n",
        "best_model_name = max(results, key=lambda x: results[x][\"R2 Score\"])\n",
        "best_model = models[best_model_name]\n",
        "best_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", best_model)\n",
        "])\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "y_pred = best_pipeline.predict(X_test)\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "\n",
        "final_results = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred})\n",
        "print(final_results.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest - Mean Absolute Error: 0.10328900000000169, R-squared Score: 0.7862192530188004\n",
            "Gradient Boosting - Mean Absolute Error: 0.11502069325002197, R-squared Score: 0.76437132473005\n",
            "Linear Regression - Mean Absolute Error: 0.28856005272919427, R-squared Score: 0.21221071048730833\n",
            "K-Nearest Neighbors - Mean Absolute Error: 0.28356000000000003, R-squared Score: 0.26261590569135196\n",
            "Support Vector Machine - Mean Absolute Error: 0.16319767777216068, R-squared Score: 0.6541413368002256\n",
            "Best Model: Random Forest\n",
            "    Actual  Predicted\n",
            "0      7.8     7.4610\n",
            "1      6.8     6.7980\n",
            "2      6.6     6.5980\n",
            "3      6.6     6.5960\n",
            "4      6.8     6.8760\n",
            "5      7.6     7.2200\n",
            "6      7.9     7.4170\n",
            "7      6.7     6.7460\n",
            "8      6.9     6.8990\n",
            "9      6.6     6.6000\n",
            "10     6.9     6.8970\n",
            "11     7.3     7.1100\n",
            "12     6.8     6.9640\n",
            "13     7.9     7.8575\n",
            "14     6.9     6.8960\n",
            "15     6.6     6.6000\n",
            "16     7.2     7.1530\n",
            "17     6.6     6.6000\n",
            "18     6.5     6.5000\n",
            "19     7.0     6.8180\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['earthquake_model.pkl']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"earthquake_1995-2023.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Selecting features and target variable\n",
        "target = \"magnitude\"\n",
        "features = [\"latitude\", \"longitude\", \"depth\", \"cdi\", \"mmi\", \"tsunami\", \"sig\", \"dmin\", \"gap\", \"nst\", \"magType\"]\n",
        "\n",
        "# Drop rows with missing target\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "for col in [\"cdi\", \"mmi\", \"sig\", \"dmin\", \"gap\", \"nst\"]:\n",
        "    df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# One-hot encode categorical features\n",
        "categorical_features = [\"magType\"]\n",
        "numerical_features = list(set(features) - set(categorical_features))\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "])\n",
        "\n",
        "# Split the dataset\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define different models\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsRegressor(n_neighbors=5),\n",
        "    \"Support Vector Machine\": SVR()\n",
        "}\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, regressor in models.items():\n",
        "    model = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"regressor\", regressor)\n",
        "    ])\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    results[name] = {\"MAE\": mae, \"R2 Score\": r2}\n",
        "    print(f\"{name} - Mean Absolute Error: {mae}, R-squared Score: {r2}\")\n",
        "\n",
        "# Select the best model\n",
        "best_model_name = max(results, key=lambda x: results[x][\"R2 Score\"])\n",
        "best_model = models[best_model_name]\n",
        "best_pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"regressor\", best_model)\n",
        "])\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "y_pred = best_pipeline.predict(X_test)\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "\n",
        "final_results = pd.DataFrame({\"Actual\": y_test.values, \"Predicted\": y_pred})\n",
        "print(final_results.head(20))\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_pipeline, \"earthquake_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved successfully as earthquake_model.pkl\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor  # Example model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"earthquake_1995-2023.csv\")\n",
        "\n",
        "# Data Preprocessing (Modify as per your dataset)\n",
        "X = df[['latitude', 'longitude', 'depth', 'cdi', 'mmi', 'tsunami', 'sig', 'dmin', 'gap', 'nst']]\n",
        "y = df['magnitude']  # Target column\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model as a pipeline\n",
        "with open(\"earthquake_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(\"Model saved successfully as earthquake_model.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
